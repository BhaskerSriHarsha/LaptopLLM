{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac29c4e2-0fb0-4417-92f5-d093c579a644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BhaskerSriHarsha\\Documents\\Environments\\pyTorch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7573100a-4027-491a-8681-16195edb7537",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_id = \"HuggingFaceTB/SmolLM-135M\"\n",
    "new_model_id = \"SmolLM-Our-Instruct-vxx\"\n",
    "tokenizer_id = \"HuggingFaceTB/SmolLM-135M-Instruct\"\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d9c72c5-395b-4152-954a-06b141fe01db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "624107fd-853f-4eeb-a409-e49897d15b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_id, device_map='auto')\n",
    "new_model = AutoModelForCausalLM.from_pretrained(new_model_id, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7fb58ba-de80-47c3-87bf-19ede3df3d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Write a python program to add two numbers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8020f65-1a4c-481b-b756-e08cda0a3336",
   "metadata": {},
   "source": [
    "## Base model response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7df1609-ae7d-4879-893b-15d2e11eb132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a python program to add two numbers.\n",
      "\n",
      "# 1. Write a python program to add two numbers.\n",
      "\n",
      "# 2. Write a python program to add two numbers.\n",
      "\n",
      "# 3. Write a python program to add two numbers.\n",
      "\n",
      "# 4. Write a python program to add two numbers.\n",
      "\n",
      "# 5. Write a python program to add two numbers.\n",
      "\n",
      "# 6. Write a python program to add two numbers.\n",
      "\n",
      "# 7. Write a python\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "outputs = base_model.generate(**inputs, max_new_tokens=100, do_sample=False)\n",
    "\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc743dc-caec-4227-9189-d9cbda5c072c",
   "metadata": {},
   "source": [
    "## Our model response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f887e84-0305-4b4f-a935-ebf63749ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{'role':'user','content':text}]\n",
    "input_text=tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "102f7187-84d7-4ef3-bba7-57192dce4e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To add two numbers, you can use the addition operator. For example, 5 + 7.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "outputs = new_model.generate(**inputs, max_new_tokens=100, do_sample=False,tokenizer=tokenizer,stop_strings=['<|im_end|>'])\n",
    "model_op = tokenizer.decode(outputs[0])[len(input_text):]\n",
    "print(model_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b220d623-f2f5-4fcd-a7bf-bbd2d34ad51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a python program to find the sum of the first n natural numbers.\n",
      "Write a python program to find the sum of the first n natural numbers.\n",
      "Write a python program to find the sum of the first n natural numbers.\n",
      "Write a python program to find the sum of the first n natural numbers.\n",
      "Write a python program to find the sum of the first n natural numbers.\n",
      "Write a python program to find the sum of the first n natural numbers.\n",
      "Write a python program\n"
     ]
    }
   ],
   "source": [
    "outputs = base_model.generate(**inputs, max_new_tokens=100, do_sample=False,tokenizer=tokenizer,stop_strings=['<|im_end|>'])\n",
    "model_op = tokenizer.decode(outputs[0])[len(input_text):]\n",
    "print(model_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8de413-d5f6-4307-810f-4b6483b33d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
